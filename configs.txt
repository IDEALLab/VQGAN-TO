# Configuration file for VQGAN ablation study
# Format: experiment_name:param1=value1,param2=value2,param3=value3
# ALL NAMES MUST BE DIFFERENT

# Baseline with default parameters
baseline:

# 1) Latent dimension ablation
latent_32:latent_dim=32
latent_16:latent_dim=16
latent_8:latent_dim=8
latent_4:latent_dim=4
latent_4_ND:latent_dim=4,disc_start=999999

# 2) Codebook vector count ablation
codebook_128:num_codebook_vectors=128
codebook_64:num_codebook_vectors=64
codebook_32:num_codebook_vectors=32

# 3) Learning rate ablation
lr_med:learning_rate=2e-04
lr_high:learning_rate=2e-03
lr_med_ND:learning_rate=2e-04,disc_start=999999
lr_high_ND:learning_rate=2e-03,disc_start=999999

# 4) Discriminator start ablation (5*215=1075, 999*215=214785)
disc_early:disc_start=1075
disc_none:disc_start=214785

# 5) Spectral normalization of the discriminator
spec_norm_disc:spectral_disc=true

# 6) Network size ablations (medium, hybrid, and small, respectively)
net_med:decoder_channels=256 256 256 128 128,encoder_channels=128 128 128 256 256 256
net_hybrid:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256
net_small:decoder_channels=128 128 128 64 64,encoder_channels=64 64 64 128 128 128

# 7) Residual blocks ablation
res_more:decoder_num_res_blocks=4,encoder_num_res_blocks=3
res_less:decoder_num_res_blocks=2,encoder_num_res_blocks=1

# 8) Attention resolution ablation
attn_med:decoder_attn_resolutions=16 32,encoder_attn_resolutions=16 32
attn_high:decoder_attn_resolutions=16 32 64,encoder_attn_resolutions=16 32 64

# Combinations after initial testing:
c1:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=8,num_codebook_vectors=64,learning_rate=2.25e-05,disc_start=999999
c2:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=8,num_codebook_vectors=64,learning_rate=2e-04,disc_start=999999
c3:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=8,num_codebook_vectors=32,learning_rate=2.25e-05,disc_start=999999
c4:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=8,num_codebook_vectors=32,learning_rate=2e-04,disc_start=999999

c5:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=64,learning_rate=2.25e-05,disc_start=999999
c6:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=64,learning_rate=2e-04,disc_start=999999
c6_repeat:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=64,learning_rate=2e-04,disc_start=999999
c7:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=32,learning_rate=2.25e-05,disc_start=999999
c8:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=32,learning_rate=2e-04,disc_start=999999
c8_repeat:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=4,num_codebook_vectors=32,learning_rate=2e-04,disc_start=999999

# Also try latent_dim 4 or even 2? Start without discriminator
# After this: pick the best above and test with different discriminator start times (0-5 epochs in or 0-5 * 215 steps). When using discriminator, likely stick to learning_rate=2.25e-05

# From c6 (best): lower latent_dim to 2, 1, and double codebook vectors to 128, 256
c9:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=2,num_codebook_vectors=128,learning_rate=2e-04,disc_start=999999
c10:decoder_channels=256 128 128 64 64,encoder_channels=64 64 64 128 128 256,latent_dim=1,num_codebook_vectors=256,learning_rate=2e-04,disc_start=999999

#################### CVQGAN ####################
cvq:is_c=true,image_channels=3,learning_rate=2e-04,disc_start=9999999,epochs=1000,sample_interval=2150
# Hint: image_channels is the number of conditions in this case